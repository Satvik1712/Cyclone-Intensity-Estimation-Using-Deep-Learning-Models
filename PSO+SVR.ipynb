{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a718fd-a6f9-4dbc-9129-be692806e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82acbe19-8a84-4f35-b393-6da59d6a2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pyswarm import pso\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Paths ---\n",
    "csv_path = \"D:/B.Tech/8th Sem/CI Lab/Project/Cylone_Intensity_IndianOcean/label.csv\"\n",
    "image_dir = \"D:/B.Tech/8th Sem/CI Lab/Project/Cylone_Intensity_IndianOcean/Infrared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3898677c-f2cc-442e-a552-9e5ed4db6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples from CSV: 15101\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load CSV ---\n",
    "df = pd.read_csv(csv_path)\n",
    "df['filepath'] = df['Filename'].apply(lambda x: os.path.join(image_dir, x))\n",
    "print(f\"Total samples from CSV: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea6c38a-b2a9-4980-813a-053d6024f50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape: (15101, 4096)\n",
      "Labels shape: (15101,)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Extract raw features from images ---\n",
    "def extract_image_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (64, 64)).astype(np.float32) / 255.0\n",
    "    return image.flatten()\n",
    "\n",
    "X = np.array([extract_image_features(p) for p in df['filepath']])\n",
    "y = df['Vmax'].values\n",
    "\n",
    "print(f\"Raw feature shape: {X.shape}\")  # (samples, features)\n",
    "print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b11a4a1-b506-4a13-bda5-8af9a3211bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features count: 2141\n",
      "Feature shape after PSO selection: (15101, 2141)\n",
      "X_test: (3021, 2141), y_test: (3021,)\n",
      "X_train: (12080, 2141), y_train: (12080,)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Load saved selected feature mask ---\n",
    "selected_mask = np.load(\"selected_features_mask.npy\")\n",
    "X_selected = X[:, selected_mask]\n",
    "print(f\"Selected features count: {np.sum(selected_mask)}\")\n",
    "print(f\"Feature shape after PSO selection: {X_selected.shape}\")\n",
    "\n",
    "# --- 5. Train-test split ---\n",
    "# split: train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb57cc8c-bb22-41c0-80c5-9827810e579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert to Tensors ---\n",
    "def to_loader(X, y):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    return DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=True)\n",
    "\n",
    "train_loader = to_loader(X_train, y_train)\n",
    "test_loader = to_loader(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdccd0f-cf00-47fb-af86-95dcbf472b53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b9f9bb-356e-46c6-8197-1993038deff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results:\n",
      "Mean Absolute Error (MAE): 3.65\n",
      "Mean Squared Error (MSE): 110.99\n",
      "R2 Score: 0.9067\n",
      "Test Evaluation Results:\n",
      "Mean Absolute Error (MAE): 14.92\n",
      "Mean Squared Error (MSE): 416.56\n",
      "R2 Score: 0.6448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train SVR model ---\n",
    "svr_model = SVR(kernel='rbf', C=100, gamma='scale', epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predict ---\n",
    "y_pred_train = svr_model.predict(X_train_scaled)\n",
    "\n",
    "# --- Train Evaluation ---\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Train Evaluation Results:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# --- Test Evaluation ---\n",
    "y_pred = svr_model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Evaluation Results:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21ee85-15c7-4684-b71d-b43f82fac892",
   "metadata": {},
   "source": [
    "## Grid Serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98151f22-e056-4ffa-95ed-4a98f59bad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Set up the parameter grid\n",
    "#    – Feel free to widen / tighten these ranges.\n",
    "# ------------------------------------------------------------------\n",
    "param_grid = {\n",
    "    'C':      [1, 10, 100, 300],\n",
    "    'gamma':  ['scale', 'auto', 0.01, 0.001],\n",
    "    'epsilon':[0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Configure the SVR and GridSearchCV\n",
    "# ------------------------------------------------------------------\n",
    "base_svr   = SVR(kernel='rbf')\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = base_svr,\n",
    "    param_grid = param_grid,\n",
    "    cv = 5,                        # 5‑fold cross‑validation\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    n_jobs = -1,                   # use all CPU cores\n",
    "    verbose = 2                    # 0 = silent, 1 = minimal, 2 = detailed\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Run the grid search\n",
    "# ------------------------------------------------------------------\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Evaluate the best model on train & test sets\n",
    "# ------------------------------------------------------------------\n",
    "best_svr = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = best_svr.predict(X_train_scaled)\n",
    "y_pred_test  = best_svr.predict(X_test_scaled)\n",
    "\n",
    "def report(y_true, y_pred, split):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{split} Results  |  MAE: {mae:.3f}  MSE: {mse:.3f}  R²: {r2:.4f}\")\n",
    "\n",
    "report(y_train, y_pred_train, \"Train\")\n",
    "report(y_test,  y_pred_test,  \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f5b36-7527-4767-81db-64a41781caae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
